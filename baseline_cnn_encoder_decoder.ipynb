{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Resconstrute\n",
    "\n",
    "- Reference : \n",
    "\n",
    "1. https://arxiv.org/pdf/2111.12417v1.pdf\n",
    "2. https://arxiv.org/pdf/2212.06714.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import visualkeras\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DATA_PATH = \"./data/gaussian/cropped/\"\n",
    "Y_DATA_PATH = \"./data/gaussian/resized/\"\n",
    "NOISE_Y_DATA_PATH = \"./only_noise/\"\n",
    "\n",
    "x_data_path_list = os.listdir(X_DATA_PATH)\n",
    "y_data_path_list = os.listdir(Y_DATA_PATH)\n",
    "y_noise_data_path_list = os.listdir(NOISE_Y_DATA_PATH)\n",
    "\n",
    "X, y, y_noise = list(), list(), list()\n",
    "for x_data_path in tqdm(x_data_path_list, desc=f'X data loading...'):   X.append(cv2.imread(X_DATA_PATH + x_data_path))\n",
    "for y_data_path in tqdm(y_data_path_list, desc=f'Y data loading...'):   y.append(cv2.imread(Y_DATA_PATH + y_data_path))\n",
    "for y_noise_data_path in tqdm(y_noise_data_path_list, desc=f'Y noise data loading...'):   y_noise.append(cv2.imread(NOISE_Y_DATA_PATH + y_noise_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)[:,:,:,0]\n",
    "y = np.array(y)[:,:,:,0]\n",
    "y_noise = np.array(y_noise)[:,:,:,0]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X.reshape(-1, 1)).reshape(X.shape)\n",
    "y = scaler.fit_transform(y.reshape(-1, 1)).reshape(y.shape)\n",
    "y_noise = scaler.fit_transform(y_noise.reshape(-1, 1)).reshape(y_noise.shape)\n",
    "\n",
    "print(f\"\"\"X shape: {X.shape}\n",
    "y shape: {y.shape}\n",
    "y_noise shape: {y_noise.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"\"\"X_train shape: {X_train.shape}\n",
    "y_train shape: {y_train.shape}\n",
    "X_test shape: {X_test.shape}\n",
    "y_test shape: {y_test.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, y_train_noise, y_test_noise = train_test_split(y_noise, y_noise, test_size=0.2, random_state=42)\n",
    "print(f\"\"\"y_train shape: {y_train_noise.shape}\n",
    "y_test shape: {y_test_noise.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randlist = np.random.randint(0, X_train.shape[0], 10)\n",
    "\n",
    "ax, fig = plt.subplots(10, 3, figsize=(10, 30))\n",
    "for i, j in zip(range(10), randlist):\n",
    "    fig[i][0].title.set_text(f\"X_train[{j}]\")\n",
    "    fig[i][1].title.set_text(f\"y_train[{j}]\")\n",
    "    fig[i][2].title.set_text(f\"y_train_noise[{j}]\")\n",
    "    fig[i][0].imshow(X_train[j], cmap='gray')\n",
    "    fig[i][1].imshow(y_train[j], cmap='gray')\n",
    "    fig[i][2].imshow(y_train_noise[j], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = layers.Input(shape=(256, 256, 1))\n",
    "\n",
    "x1 = layers.Conv2D(16, (3, 3), strides=2, activation='gelu')(input_layer)\n",
    "x1_skip2 = x1\n",
    "x1 = layers.Conv2D(16, (3, 3), activation='gelu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.Conv2D(16, (3, 3), activation='gelu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "\n",
    "'''First Transformer Block\n",
    "----------> Start'''\n",
    "x1 = layers.Conv2D(16, (3, 3), strides=2, activation='gelu')(x1)\n",
    "x1_skip = layers.Conv2D(16, (3, 3), activation='gelu')(x1)\n",
    "x1 = layers.DepthwiseConv2D((3, 3), strides=1, activation='gelu')(x1)\n",
    "x1 = layers.Concatenate()([x1, x1])\n",
    "\n",
    "x1 = layers.LayerNormalization()(x1)\n",
    "x2 = layers.Dense(256)(x1)\n",
    "x1 = layers.DepthwiseConv2D((3, 3), strides=3, activation='gelu')(x1)\n",
    "x3 = layers.Dense(256)(x1)\n",
    "x1 = layers.Concatenate()([x1, x3])\n",
    "\n",
    "x1 = layers.Reshape((76, 76, 18))(x1)\n",
    "x1 = layers.Conv2D(32, (2, 2), strides=3, activation='gelu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.Conv2D(32, (2, 2), strides=2, activation='gelu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "\n",
    "x1 = layers.Conv2D(32, (2, 2), strides=2, activation='gelu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x3_skip = x1\n",
    "x3_skip = layers.MaxPool2D((2, 2))(x3_skip)\n",
    "\n",
    "## Guide \n",
    "x1 = layers.LayerNormalization()(x1)\n",
    "x1 = layers.Conv2D(16, (1, 1), strides=2, activation='gelu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.DepthwiseConv2D((3, 3), strides=1, activation='gelu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.Conv2D(16, (1, 1), strides=1, activation='gelu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "'''First Transformer Block\n",
    "----------> End'''\n",
    "\n",
    "# Noise Image Input\n",
    "latent_space = x1\n",
    "x2 = layers.Conv2DTranspose(32, (3, 3), strides=3, activation='gelu')(latent_space)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Conv2DTranspose(32, (6, 6), strides=2, activation='gelu')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "\n",
    "x2 = layers.Conv2DTranspose(16, (9, 9), strides=2, activation='gelu')(x2)\n",
    "x2 = layers.Conv2DTranspose(16, (7, 7), strides=2, activation='gelu')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Conv2DTranspose(16, (4, 4), activation='gelu')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "\n",
    "x2 = layers.Conv2DTranspose(16, (5, 5), strides=2, activation='gelu')(x2)\n",
    "x2 = layers.LayerNormalization()(x2)\n",
    "\n",
    "x2 = layers.Conv2DTranspose(8, (3, 3), strides=2, activation='gelu')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Conv2DTranspose(1, (2, 2), strides=1, activation='gelu')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "\n",
    "x2 = layers.Reshape((256, 256, 1), name=\"noise_image\")(x2)\n",
    "y2 = x2\n",
    "\n",
    "'''Second Transformer Block\n",
    "----------> Start'''\n",
    "x1 = layers.Conv2DTranspose(32, (3, 3), strides=3, activation='gelu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.Concatenate()([x1, x3_skip])\n",
    "x1 = layers.Conv2DTranspose(32, (6, 6), strides=2, activation='gelu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "\n",
    "x1 = layers.Conv2DTranspose(16, (9, 9), strides=2, activation='gelu')(x1)\n",
    "x1 = layers.Conv2DTranspose(16, (7, 7), strides=2, activation='gelu')(x1)\n",
    "x1 = layers.Concatenate()([x1, x1_skip])\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.Conv2DTranspose(16, (4, 4), activation='gelu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "\n",
    "x1 = layers.Conv2DTranspose(16, (5, 5), strides=2, activation='gelu')(x1)\n",
    "x1 = layers.Concatenate()([x1, x1_skip2])\n",
    "x1 = layers.LayerNormalization()(x1)\n",
    "\n",
    "x1 = layers.Conv2DTranspose(8, (3, 3), strides=2, activation='gelu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x1 = layers.Conv2DTranspose(1, (2, 2), strides=1, activation='gelu')(x1)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "'''Second Transformer Block\n",
    "----------> End'''\n",
    "\n",
    "decoded_image = layers.Reshape((256, 256, 1), name=\"reconstructed_image\")(x1)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=[decoded_image, y2])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimzier = tf.keras.optimizers.Adam(learning_rate=0.003)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer=optimzier, loss=[loss, loss], metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDir = './checkpoint_with_noise/' # 이 경로에 best 모델이 저장된다.\n",
    "model_names = outDir + 'weights-{epoch}-{val_noise_image_loss:.8f}-{val_reconstructed_image_loss:.8f}.h5'\n",
    "def get_callbacks(patience = 50):\n",
    "    model_checkpoint = ModelCheckpoint(model_names, monitor='val_reconstructed_image_loss', verbose=1, save_best_only=True, period = 1)\n",
    "    callbacks = [model_checkpoint]\n",
    "    return callbacks\n",
    "\n",
    "callback = get_callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    y_train, [y_train, y_train_noise],\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_data=(y_test, [y_test, y_test_noise]),\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(train_loss, 'r', label='train loss')\n",
    "plt.plot(val_loss, 'b', label='val loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(10):\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, 10, i + 1 + 10)\n",
    "    plt.imshow(y_pred[0][i].reshape(256, 256))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display input image\n",
    "    ax = plt.subplot(2, 10, i + 1)\n",
    "    plt.imshow(y_test[i].reshape(256, 256))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_path = sorted(os.listdir(outDir))\n",
    "pretrained_model_file = outDir + \"weights-37-0.69992024-0.59163594.h5\"\n",
    "print(f\"pretrained_model_file: {pretrained_model_file}\")\n",
    "\n",
    "pretrained_model = keras.models.load_model(pretrained_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pretrained_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"y_pred shape: {y_pred[0].shape}\n",
    "y_test shape: {y_test.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SELECT = 23\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "ax[0].imshow(X_test[IMAGE_SELECT])\n",
    "ax[0].set_title('Input Image')\n",
    "ax[1].imshow(y_pred[0][IMAGE_SELECT])\n",
    "ax[1].set_title('Predicted Image')\n",
    "ax[2].imshow(y_test[IMAGE_SELECT])\n",
    "ax[2].set_title('Ground Truth Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
